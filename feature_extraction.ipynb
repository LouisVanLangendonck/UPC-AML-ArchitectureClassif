{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOkA1ZwOdEbrKFumVXaXx0n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LouisVanLangendonck/UPC-AML-ArchitectureClassif/blob/main/feature_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WDhs4F-_dGi",
        "outputId": "d6ffbf75-0c6b-43e9-fe52-b73f0a701f0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF version: 2.9.2\n",
            "Hub version: 0.12.0\n",
            "keras version: 2.9.0\n",
            "GPU is NOT AVAILABLE\n"
          ]
        }
      ],
      "source": [
        "import itertools\n",
        "import os\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import keras\n",
        "import random\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"Hub version:\", hub.__version__)\n",
        "print(\"keras version:\", keras.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJEYy0glANJS",
        "outputId": "c102be4e-858b-4b14-d5a7-a33546b8d0a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = '/content/drive/MyDrive/FIB-2022-2023/aml/data/unzipped/train+val'\n",
        "test_data = '/content/drive/MyDrive/FIB-2022-2023/aml/data/unzipped/test'\n",
        "print(os.listdir(train_data))"
      ],
      "metadata": {
        "id": "KC7PtS5VAVgS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cc99f13-27d7-41a8-f556-58b80493597f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['modernism', 'gothic', 'contemporary', 'baroque', 'noucentisme', 'romanesque', 'neoclassicism']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "batch_size = 150\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "        train_data, \n",
        "        target_size = (224,224),\n",
        "        batch_size=batch_size, \n",
        "        class_mode = 'categorical')\n",
        "\n",
        "test_generator = datagen.flow_from_directory(\n",
        "        test_data, \n",
        "        target_size = (224,224),\n",
        "        batch_size=batch_size, \n",
        "        class_mode = 'categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xx14AG4LlreZ",
        "outputId": "495b94c4-419a-4086-f62b-24469cb38669"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 12618 images belonging to 7 classes.\n",
            "Found 3109 images belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import VGG19\n",
        "from keras import layers\n",
        "from keras import models\n",
        "\n",
        "feature_extractor = VGG19(\n",
        "    weights='imagenet',\n",
        "    include_top=False\n",
        ")"
      ],
      "metadata": {
        "id": "9v3pSelUltsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nr_train_images = 12618\n",
        "nr_test_images = 3109\n",
        "nr_of_target_classes = 7"
      ],
      "metadata": {
        "id": "Zj71WyH6mVTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "#pip install tqdm\n",
        "from tqdm import tqdm\n",
        "\n",
        "def extract_features(generator, sample_count):\n",
        "    print('Beginning feature extraction for {} samples in {} batches:'.format(sample_count, int(np.ceil(sample_count/batch_size))))\n",
        "    with tqdm(total=int(np.ceil(sample_count/batch_size)), position=0, leave=True) as pbar:\n",
        "        features = np.zeros(shape = (sample_count,7,7,512))\n",
        "        labels = np.zeros(shape = (sample_count, nr_of_target_classes))\n",
        "        i = 0\n",
        "        for inputs_batch, labels_batch in generator:\n",
        "            pbar.update(n=1)\n",
        "            features_batch = feature_extractor.predict(inputs_batch, verbose=0)\n",
        "            features[i*batch_size:(i+1)*batch_size] = features_batch\n",
        "            labels[i*batch_size : (i+1)*batch_size] = labels_batch\n",
        "            i += 1\n",
        "            if (i+1)*batch_size >= sample_count:\n",
        "                print('final batch')\n",
        "                features_batch = feature_extractor.predict(inputs_batch, verbose=0)\n",
        "                features[i*batch_size:sample_count] = features_batch[0:sample_count-(i*batch_size)]\n",
        "                labels[i*batch_size:sample_count] = labels_batch[0:sample_count-(i*batch_size)]\n",
        "                break\n",
        "    print('Features extracted!')\n",
        "    print('Shape of feature vector:{}'.format(features.shape))\n",
        "    print('Shape of labels vector:{}'.format(labels.shape))\n",
        "    return features, labels\n",
        "\n",
        "print('Train Feature Extraction:')\n",
        "train_features, train_labels = extract_features(train_generator, nr_train_images)\n",
        "print('Test Feature Extraction:')\n",
        "test_features, test_labels = extract_features(test_generator, nr_test_images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fb0gw2fBmKe7",
        "outputId": "6bef9c7d-d136-41fb-c224-dbe6f88cd431"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Feature Extraction:\n",
            "Beginning feature extraction for 12618 samples in 85 batches:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 84/85 [2:15:13<01:35, 95.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final batch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 84/85 [2:16:33<01:37, 97.54s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features extracted!\n",
            "Shape of feature vector:(12618, 7, 7, 512)\n",
            "Shape of labels vector:(12618, 7)\n",
            "Test Feature Extraction:\n",
            "Beginning feature extraction for 3109 samples in 21 batches:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▌| 20/21 [31:55<01:38, 98.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final batch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 20/21 [33:14<01:39, 99.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features extracted!\n",
            "Shape of feature vector:(3109, 7, 7, 512)\n",
            "Shape of labels vector:(3109, 7)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_features = np.asarray([(train_features, train_labels), (test_features, test_labels)], dtype=object)\n",
        "np.save('/content/drive/MyDrive/FIB-2022-2023/aml/models/VGG19_features.npy', all_features)"
      ],
      "metadata": {
        "id": "SgXiXo3R27Py"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp_train_features = np.reshape(train_features, (train_images, 7*7*512))\n",
        "inp_val_features = np.reshape(val_features, (val_images, 7*7*512))\n",
        "inp_test_features = np.reshape(test_features, (test_images, 7*7*512))"
      ],
      "metadata": {
        "id": "Gt2fl7dL4mTM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}