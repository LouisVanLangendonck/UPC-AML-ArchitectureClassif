{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select\n",
    "import time \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "driver = webdriver.Edge()\n",
    "\n",
    "def scrape_style(url, style_name):\n",
    "    big_iter = 780\n",
    "    base = 'http://invarquit.cultura.gencat.cat/Cerca/'  \n",
    "    driver.get(url)\n",
    "    first_building = driver.find_elements(By.CLASS_NAME, \"enlacedestacado\")[0] #Do this only once. From here on uses other button\n",
    "    first_building.click()\n",
    "    download_images(driver.current_url, style=style_name, big_it=big_iter) #To click trough all images and download each for first \n",
    "    next_buttons = driver.find_elements(By.TAG_NAME, 'img') \n",
    "    for button in next_buttons:\n",
    "        if 'endavant' in button.get_attribute('src'):\n",
    "            if \"public\" in button.get_attribute('title'):\n",
    "                next_building = button\n",
    "    next_building.click() #Go to next building\n",
    "    contin=True\n",
    "    while contin:\n",
    "        big_iter += 1\n",
    "        next_buttons = driver.find_elements(By.TAG_NAME, 'img')\n",
    "        for button in next_buttons:\n",
    "            if 'endavant' in button.get_attribute('src'):\n",
    "                if \"public\" in button.get_attribute('title') and not \"Off\" in button.get_attribute('title'):\n",
    "                    next_building = button #There is a next building \n",
    "                elif \"public\" in button.get_attribute('title') and \"Off\" in button.get_attribute('title'): #Last building of style\n",
    "                    download_images(driver.current_url, style=style_name, big_it=big_iter) #To click trough all images and download each \n",
    "                    contin = False   \n",
    "        if contin:\n",
    "            next_building.click()\n",
    "            download_images(driver.current_url, style=style_name, big_it=big_iter) #To click trough all images and download each \n",
    "\n",
    "\n",
    "def download_images(url, style, big_it):\n",
    "    it = 0\n",
    "    try:\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "        candid_dupl = soup.find_all(class_ = \"taulesDeDins\") \n",
    "        if len(candid_dupl[0]) == 5:                    #To check if only a single style label is assigned to the building\n",
    "            img_source = driver.find_element(By.ID, \"imatgeACanviar\").get_attribute(\"src\")\n",
    "            urllib.request.urlretrieve(img_source, '{}/{}-{}-{}.jpg'.format(style,style, big_it, it)) #Naming convention\n",
    "            next_buttons = driver.find_elements(By.TAG_NAME, 'img')\n",
    "            for button in next_buttons:\n",
    "                if 'endavant' in button.get_attribute('src'):\n",
    "                    if not \"public\" in button.get_attribute('title'):\n",
    "                        next_img = button\n",
    "            next_img.click()\n",
    "            new_img_source = driver.find_element(By.ID, \"imatgeACanviar\").get_attribute(\"src\")\n",
    "            while new_img_source != img_source and it < 7: #Download at most 7 images\n",
    "                it += 1\n",
    "                urllib.request.urlretrieve(new_img_source, '{}/{}-{}-{}.jpg'.format(style,style, big_it, it))\n",
    "                next_buttons = driver.find_elements(By.TAG_NAME, 'img')\n",
    "                for button in next_buttons:\n",
    "                    if 'endavant' in button.get_attribute('src'):\n",
    "                        if not \"public\" in button.get_attribute('title'):\n",
    "                            next_img = button\n",
    "                next_img.click()\n",
    "                img_source = new_img_source\n",
    "                new_img_source = driver.find_element(By.ID, \"imatgeACanviar\").get_attribute(\"src\")   \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "style_list = ['baroque', 'contemporary', 'gothic', 'modernism', 'neoclassicism', 'noucentisme', 'renaissance', 'romanesque']\n",
    "corr_url = ['http://invarquit.cultura.gencat.cat/Cerca/Llista?Consulta=MCU4K0JhcnJvYyU%3D', 'http://invarquit.cultura.gencat.cat/Cerca/Llista?Consulta=MCU4K0RhcnJlcmVzIHRlbmTDqG5jaWVzJQ%3D%3D',\n",
    "'http://invarquit.cultura.gencat.cat/Cerca/Llista?Consulta=MCU4K0fDsnRpYyU%3D', 'http://invarquit.cultura.gencat.cat/Cerca/Llista?Consulta=MCU4K01vZGVybmlzbWUl', 'http://invarquit.cultura.gencat.cat/Cerca/Llista?Consulta=MCU4K05lb2NsYXNzaWNpc21lJQ%3D%3D',\n",
    "'http://invarquit.cultura.gencat.cat/Cerca/Llista?Consulta=MCU4K05vdWNlbnRpc21lJQ%3D%3D', 'http://invarquit.cultura.gencat.cat/Cerca/Llista?Consulta=MCU4K1JlbmFpeGVtZW50JQ%3D%3D', \n",
    "'http://invarquit.cultura.gencat.cat/Cerca/Llista?Consulta=MCU4K1JvbcOgbmljJQ%3D%3D'] #Loop of all links necessary. Can easily be extended.\n",
    "\n",
    "for idx, style in enumerate(style_list): #Actual command to run and scrape all. Note that everything will take a long time. \n",
    "    URL = corr_url[idx]\n",
    "    scrape_style(URL, style)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('aml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7c8e7d7f0d100c09d28d7f04e5e774ff9d2a2cdbc50493979813ecd99615844"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
